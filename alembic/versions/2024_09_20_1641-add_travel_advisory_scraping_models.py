"""Add travel advisory scraping models

Revision ID: add_travel_advisory_scraping_models
Revises:
Create Date: 2024-09-20 16:41:00.000000

"""
from alembic import op
import sqlalchemy as sa
from sqlalchemy.dialects import postgresql

# revision identifiers, used by Alembic.
revision = 'add_travel_advisory_scraping_models'
down_revision = None
branch_labels = None
depends_on = None


def upgrade() -> None:
    # ### commands auto generated by Alembic - please adjust! ###
    op.create_table('travel_advisories',
    sa.Column('id', postgresql.UUID(as_uuid=True), nullable=False),
    sa.Column('url', sa.String(length=2048), nullable=False),
    sa.Column('source', sa.String(length=100), nullable=False),
    sa.Column('country', sa.String(length=100), nullable=False),
    sa.Column('title', sa.Text(), nullable=False),
    sa.Column('content', sa.Text(), nullable=False),
    sa.Column('content_hash', sa.String(length=64), nullable=False),
    sa.Column('risk_level', sa.String(length=200), nullable=True),
    sa.Column('last_updated_source', sa.String(length=100), nullable=True),
    sa.Column('metadata', sa.JSON(), nullable=True),
    sa.Column('scraped_at', sa.DateTime(), nullable=False),
    sa.Column('created_at', sa.DateTime(), nullable=False),
    sa.Column('updated_at', sa.DateTime(), nullable=False),
    sa.Column('is_active', sa.Boolean(), nullable=True),
    sa.Column('content_changed', sa.Boolean(), nullable=True),
    sa.PrimaryKeyConstraint('id')
    )
    op.create_index('idx_travel_advisories_content_hash', 'travel_advisories', ['content_hash'], unique=False)
    op.create_index('idx_travel_advisories_country_source', 'travel_advisories', ['country', 'source'], unique=False)
    op.create_index('idx_travel_advisories_risk_level', 'travel_advisories', ['risk_level'], unique=False)
    op.create_index('idx_travel_advisories_scraped_at', 'travel_advisories', ['scraped_at'], unique=False)
    op.create_index('idx_travel_advisories_url', 'travel_advisories', ['url'], unique=False)

    op.create_table('scraping_logs',
    sa.Column('id', postgresql.UUID(as_uuid=True), nullable=False),
    sa.Column('source', sa.String(length=100), nullable=False),
    sa.Column('scraping_session_id', postgresql.UUID(as_uuid=True), nullable=False),
    sa.Column('status', sa.String(length=50), nullable=False),
    sa.Column('total_countries', sa.Integer(), nullable=True),
    sa.Column('successful_scrapes', sa.Integer(), nullable=True),
    sa.Column('failed_scrapes', sa.Integer(), nullable=True),
    sa.Column('new_content_count', sa.Integer(), nullable=True),
    sa.Column('updated_content_count', sa.Integer(), nullable=True),
    sa.Column('duration_seconds', sa.Float(), nullable=True),
    sa.Column('error_message', sa.Text(), nullable=True),
    sa.Column('metadata', sa.JSON(), nullable=True),
    sa.Column('started_at', sa.DateTime(), nullable=False),
    sa.Column('completed_at', sa.DateTime(), nullable=True),
    sa.Column('created_at', sa.DateTime(), nullable=False),
    sa.PrimaryKeyConstraint('id')
    )
    op.create_index('idx_scraping_logs_session_id', 'scraping_logs', ['scraping_session_id'], unique=False)
    op.create_index('idx_scraping_logs_source', 'scraping_logs', ['source'], unique=False)
    op.create_index('idx_scraping_logs_started_at', 'scraping_logs', ['started_at'], unique=False)
    op.create_index('idx_scraping_logs_status', 'scraping_logs', ['status'], unique=False)

    op.create_table('content_change_events',
    sa.Column('id', postgresql.UUID(as_uuid=True), nullable=False),
    sa.Column('advisory_id', postgresql.UUID(as_uuid=True), nullable=False),
    sa.Column('change_type', sa.String(length=50), nullable=False),
    sa.Column('previous_hash', sa.String(length=64), nullable=True),
    sa.Column('new_hash', sa.String(length=64), nullable=True),
    sa.Column('previous_risk_level', sa.String(length=200), nullable=True),
    sa.Column('new_risk_level', sa.String(length=200), nullable=True),
    sa.Column('change_summary', sa.Text(), nullable=True),
    sa.Column('metadata', sa.JSON(), nullable=True),
    sa.Column('detected_at', sa.DateTime(), nullable=False),
    sa.Column('created_at', sa.DateTime(), nullable=False),
    sa.PrimaryKeyConstraint('id')
    )
    op.create_index('idx_content_change_events_advisory_id', 'content_change_events', ['advisory_id'], unique=False)
    op.create_index('idx_content_change_events_change_type', 'content_change_events', ['change_type'], unique=False)
    op.create_index('idx_content_change_events_detected_at', 'content_change_events', ['detected_at'], unique=False)
    # ### end Alembic commands ###


def downgrade() -> None:
    # ### commands auto generated by Alembic - please adjust! ###
    op.drop_index('idx_content_change_events_detected_at', table_name='content_change_events')
    op.drop_index('idx_content_change_events_change_type', table_name='content_change_events')
    op.drop_index('idx_content_change_events_advisory_id', table_name='content_change_events')
    op.drop_table('content_change_events')

    op.drop_index('idx_scraping_logs_status', table_name='scraping_logs')
    op.drop_index('idx_scraping_logs_started_at', table_name='scraping_logs')
    op.drop_index('idx_scraping_logs_source', table_name='scraping_logs')
    op.drop_index('idx_scraping_logs_session_id', table_name='scraping_logs')
    op.drop_table('scraping_logs')

    op.drop_index('idx_travel_advisories_url', table_name='travel_advisories')
    op.drop_index('idx_travel_advisories_scraped_at', table_name='travel_advisories')
    op.drop_index('idx_travel_advisories_risk_level', table_name='travel_advisories')
    op.drop_index('idx_travel_advisories_country_source', table_name='travel_advisories')
    op.drop_index('idx_travel_advisories_content_hash', table_name='travel_advisories')
    op.drop_table('travel_advisories')
    # ### end Alembic commands ###